–ù–∏–∂–µ –ø–æ–ª–Ω—ã–π structure.md —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –æ–ø–∏—Å–∞–Ω–∏—è–º–∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ Team Assistant –∏ –Ω–æ–≤–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è —á–µ—Ä–µ–∑ Perplexity, –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ.
‚Äã

text
# MCP Server & Chat Integration Project with RAG + Git + Support + Team Assistant + Local LLM + Analytics

## –û–±—â–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
–ü–æ–ª–Ω–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ MCP (Model Context Protocol) —Å–µ—Ä–≤–µ—Ä–æ–≤ —Å React-—á–∞—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º, **RAG (Retrieval-Augmented Generation)** —Å–∏—Å—Ç–µ–º–æ–π, **Support Assistant**, **Team Assistant**, **–ª–æ–∫–∞–ª—å–Ω–æ–π LLM (Ollama)** –∏ **Analytics Assistant** –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–≥–æ–≤ –∏ –ø—Ä–æ–¥—É–∫—Ç–æ–≤–æ–π –≤–æ—Ä–æ–Ω–∫–∏. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –≤–∫–ª—é—á–∞–µ—Ç –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å—ã –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–¥–∞—á–∞–º–∏, –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏, GitHub API, Docker, Git-–æ–ø–µ—Ä–∞—Ü–∏—è–º–∏, Document Indexing Pipeline, –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥–æ–π, –ª–æ–∫–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏. [file:86]

## Deployment Architecture

### Production Endpoints
- **Frontend (Vercel)**: `https://your-app.vercel.app`
  - React 18 + Vite
  - Serverless Functions
  - Environment: VITE_API_URL
  
- **Backend (Railway)**: `https://your-backend.railway.app`
  - Node.js Express API
  - Nixpacks builder
  - Root Directory: `/server`
  - Environment: PORT=4000 (Railway –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)

- **Local LLM (Ollama)**: `http://localhost:11434`
  - –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–æ –Ω–∞ –º–∞—à–∏–Ω–µ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞
  - –ú–æ–¥–µ–ª–∏: gemma3:4b, llama3.2:3b, nomic-embed-text
  - –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ REST API

### GitHub Actions CI/CD Pipeline

**Workflow —Ñ–∞–π–ª**: `.github/workflows/deploy.yml`

```yaml
name: Deploy to Production

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  deploy-frontend:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Deploy to Vercel
        uses: amondnet/vercel-action@v25
        with:
          vercel-token: ${{ secrets.VERCEL_TOKEN }}
          vercel-org-id: ${{ secrets.VERCEL_ORG_ID }}
          vercel-project-id: ${{ secrets.VERCEL_PROJECT_ID }}
          working-directory: ./client
          vercel-args: '--prod'
          
  deploy-backend:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Deploy to Railway
        run: |
          npm install -g @railway/cli
          railway up --service backend
        env:
          RAILWAY_TOKEN: ${{ secrets.RAILWAY_TOKEN }}
          
  notify:
    needs: [deploy-frontend, deploy-backend]
    runs-on: ubuntu-latest
    steps:
      - name: Discord Notification
        uses: sarisia/actions-status-discord@v1
        with:
          webhook: ${{ secrets.DISCORD_WEBHOOK }}
          title: "Deployment Complete"
          description: |
            ‚úÖ Frontend: ${{ secrets.VERCEL_URL }}
            ‚úÖ Backend: ${{ secrets.RAILWAY_URL }}
GitHub Secrets Configuration
Required Secrets (Settings ‚Üí Secrets and variables ‚Üí Actions):

Secret Name	Description	Source
VERCEL_TOKEN	Vercel Access Token	vercel.com ‚Üí Account Settings ‚Üí Tokens
VERCEL_ORG_ID	Vercel Organization ID	vercel.com/account ‚Üí Settings ‚Üí General ‚Üí Your ID
VERCEL_PROJECT_ID	Vercel Project ID	vercel.com/dashboard ‚Üí Project ‚Üí Settings ‚Üí Project ID
RAILWAY_TOKEN	Railway API Token	railway.app ‚Üí Account Settings ‚Üí Tokens
PERPLEXITY_API_KEY	Perplexity AI API Key	perplexity.ai/settings/api
DOCKER_USERNAME	Docker Hub Username	hub.docker.com ‚Üí Account
DOCKER_PASSWORD	Docker Hub Access Token	hub.docker.com ‚Üí Account Settings ‚Üí Security
DISCORD_WEBHOOK	Discord Webhook URL	Discord ‚Üí Channel Settings ‚Üí Integrations ‚Üí Webhooks
VERCEL_URL	Frontend Production URL	–ü–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –¥–µ–ø–ª–æ—è
RAILWAY_URL	Backend Production URL	–ü–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –¥–µ–ø–ª–æ—è
–°—Ç–µ–∫ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π
–Ø–∑—ã–∫ backend: JavaScript (Node.js ESM)

–Ø–∑—ã–∫ frontend: JavaScript (React 18)

–§—Ä–µ–π–º–≤–æ—Ä–∫–∏: Express.js, React, Vite

AI/LLM:

Perplexity API (sonar model) - –æ–±–ª–∞—á–Ω–∞—è

Ollama (gemma3:4b, llama3.2:3b) - –ª–æ–∫–∞–ª—å–Ω–∞—è

MCP SDK: @modelcontextprotocol/sdk

–ë–∏–±–ª–∏–æ—Ç–µ–∫–∏: Axios, node-fetch, node-cron, dockerode

–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã: Docker, Docker Compose, Git

Deployment: Vercel (Frontend), Railway (Backend)

CI/CD: GitHub Actions

–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
text
AI_Challenge_23/
‚îú‚îÄ‚îÄ .github/                           # üÜï GitHub Actions CI/CD
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ deploy.yml                 # Deployment pipeline
‚îÇ
‚îú‚îÄ‚îÄ server/                            # Backend (Node.js) - Railway
‚îÇ   ‚îú‚îÄ‚îÄ index.js                       # Express —Å–µ—Ä–≤–µ—Ä (PORT=4000)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ envBootstrap.js                # üÜï Bootstrap env (file.env ‚Üí process.env)
‚îÇ   ‚îú‚îÄ‚îÄ check-env.js                   # üÜï –£—Ç–∏–ª–∏—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ MCP Clients & Services
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mcpClient.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ragMcpClient.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gitMcpClient.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ supportMcpClient.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ localLlmClient.js         # –ö–ª–∏–µ–Ω—Ç –¥–ª—è Ollama (–ª–æ–∫–∞–ª—å–Ω–∞—è LLM)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Service Layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ragService.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ assistantService.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ supportAssistantService.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ teamAssistantService.js   # üîÑ –û–±–Ω–æ–≤–ª—ë–Ω: Perplexity + –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ñ–∏–ª–µ–π
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ userPersonalizationService.js  # üÜï –ü—Ä–æ—Ñ–∏–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (–°–µ—Ä–≥–µ–π, –∏ –¥—Ä.)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ documentIndexer.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analyticsService.js       # –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ª–æ–≥–æ–≤/–≤–æ—Ä–æ–Ω–∫–∏
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analyticsChatService.js   # LLM-–æ–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ analyticsService
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Configuration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analyticsConfig.js        # –ü—É—Ç–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (ANALYTICS_CSV/LOG/JSON)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ollamaConfig.js           # –ö–æ–Ω—Ñ–∏–≥ –º–æ–¥–µ–ª–µ–π –∏ –ø—Ä–µ—Å–µ—Ç–æ–≤
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ promptTemplates.js        # –®–∞–±–ª–æ–Ω—ã –ø—Ä–æ–º–ø—Ç–æ–≤ (–≤–∫–ª—é—á–∞—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ MCP Servers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ documents-mcp.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ task-mcp-server.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ git-mcp-server.js         # v1.2.1 (Railway compatible)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ docker-mcp-server.js
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Orchestration & Utils
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent-orchestrator.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ githubTools.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ githubService.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prReviewService.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ health-check.js           # /api/health –¥–ª—è CI/CD –∏ Railway
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mcpSerialize.js
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Data Storage
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ documents/                # Markdown –¥–æ–∫—É–º–µ–Ω—Ç—ã
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ indexes/                  # JSON –∏–Ω–¥–µ–∫—Å—ã (343 embeddings)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data/                     # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ events.csv            # –°–æ–±—ã—Ç–∏—è (timestamp, level, route, status_code)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ errors.log            # –õ–æ–≥–∏ –æ—à–∏–±–æ–∫ (ERROR [route=...])
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ funnel.json           # –í–æ—Ä–æ–Ω–∫–∞: [{ step, users }, ...]
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tasks.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ userProfiles/             # üÜï JSON‚Äë–ø—Ä–æ—Ñ–∏–ª–∏ –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ Team Assistant
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ luno-o.json           # –ü—Ä–æ—Ñ–∏–ª—å –°–µ—Ä–≥–µ—è (—è–∑—ã–∫, —Å—Ç–µ–∫, —Å—Ç–∏–ª—å –æ—Ç–≤–µ—Ç–æ–≤)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Configuration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ file.env                  # –õ–æ–∫–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ (OLLAMA_URL, OLLAMA_MODEL, ANALYTICS_*)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ file.env.production       # Production-–∫–æ–Ω—Ñ–∏–≥ (Railway)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ railway.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ railway.toml
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îÇ
‚îú‚îÄ‚îÄ client/                            # Frontend (React + Vite) - Vercel
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.jsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.jsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ChatPage.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AssistantPage.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SupportPage.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ TeamAssistantPage.jsx       # üîÑ –û–±–Ω–æ–≤–ª—ë–Ω: LLM Switcher + —Ñ–ª–∞–≥ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ LlmOptimizationPage.jsx     # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–π LLM
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AnalyticsPage.jsx          # UI –¥–ª—è Analytics Assistant
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ChatMessageList.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ChatInput.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AnalyticsQueryForm.jsx     # –§–æ—Ä–º–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –∞–Ω–∞–ª–∏—Ç–∏–∫—É
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AnalyticsResultView.jsx    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –∏ –∞–≥—Ä–µ–≥–∞—Ç–æ–≤
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useTeamAssistant.js        # –õ–æ–≥–∏–∫–∞ –≤—ã–∑–æ–≤–∞ /api/team/ask —Å personalizationEnabled
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ styles/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ TeamAssistantPage.css      # üîÑ –°—Ç–∏–ª–∏ –¥–ª—è LLM Switcher –∏ –±–µ–π–¥–∂–µ–π –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ LlmOptimizationPage.css    # –°—Ç–∏–ª–∏ –¥–ª—è LLM –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ AnalyticsPage.css          # –°—Ç–∏–ª–∏ –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ .env                           # Vercel Environment Variables
‚îÇ   ‚îú‚îÄ‚îÄ vercel.json                    # Vercel config
‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îÇ
‚îú‚îÄ‚îÄ scripts/                           # –°–∫—Ä–∏–ø—Ç—ã –¥–ª—è —Ç–µ—Å—Ç–æ–≤ –∏ –æ—Ç–ª–∞–¥–∫–∏
‚îÇ   ‚îú‚îÄ‚îÄ test-docker-chain.sh          # –ü—Ä–æ–≤–µ—Ä–∫–∞ Docker-—Ü–µ–ø–æ—á–∫–∏ (build, run, MCP)
‚îÇ   ‚îú‚îÄ‚îÄ test-rag-compare.sh           # –ó–∞–ø—É—Å–∫ RAG —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (with/without RAG, rerank)
‚îÇ   ‚îú‚îÄ‚îÄ test-search.js                # –¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º —á–µ—Ä–µ–∑ MCP
‚îÇ   ‚îî‚îÄ‚îÄ health-check-local.sh         # –õ–æ–∫–∞–ª—å–Ω—ã–π health check
‚îÇ
‚îî‚îÄ‚îÄ structure.md                       # –≠—Ç–æ—Ç —Ñ–∞–π–ª (v1.5.0+)
Deployment Configuration
Railway (Backend)
–§–∞–π–ª: server/railway.json

json
{
  "builder": "NIXPACKS",
  "deploy": {
    "startCommand": "node index.js",
    "healthcheckPath": "/api/health",
    "restartPolicyType": "ON_FAILURE"
  }
}
Environment Variables (Railway Dashboard):

bash
PERPLEXITY_API_KEY=pplx-xxxxxxxxxxxx
PERPLEXITY_MODEL=sonar
REPO_PATH=/app/repo
PORT=4000  # Auto-injected by Railway
NODE_ENV=production
Root Directory: /server (Settings ‚Üí Source ‚Üí Root Directory)

Vercel (Frontend)
–§–∞–π–ª: client/vercel.json

json
{
  "buildCommand": "npm run build",
  "outputDirectory": "dist",
  "installCommand": "npm install",
  "framework": "vite",
  "routes": [
    { "src": "/[^.]+", "dest": "/", "status": 200 }
  ]
}
Environment Variables (Vercel Dashboard):

bash
VITE_API_URL=https://your-backend.railway.app
NODE_VERSION=20
Ollama (Local LLM)
–£—Å—Ç–∞–Ω–æ–≤–∫–∞ (Windows):

bash
# 1. –°–∫–∞—á–∞—Ç—å —Å ollama.com
# 2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞ localhost:11434

# 3. –°–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª–∏
ollama pull gemma3:4b
ollama pull llama3.2:3b
ollama pull nomic-embed-text

# 4. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å
ollama list
curl http://localhost:11434
Environment Variables (Local Development):

bash
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=gemma3:4b
Development vs Production
Local Development
bash
# Terminal 1 - Ollama (–µ—Å–ª–∏ –Ω–µ –∑–∞–ø—É—â–µ–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
ollama serve

# Terminal 2 - Backend
cd server
npm install
npm run dev  # http://localhost:4000

# Terminal 3 - Frontend  
cd client
npm install
npm run dev  # http://localhost:5173
Production (GitHub Actions)
bash
git add .
git commit -m "feat: deploy update"
git push origin main

# üöÄ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –¥–µ–ø–ª–æ–π:
# 1. GitHub Actions –∑–∞–ø—É—Å–∫–∞–µ—Ç workflow
# 2. Frontend ‚Üí Vercel (serverless)
# 3. Backend ‚Üí Railway (container)
# 4. Discord notification —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
API Endpoints (Production)
Base URL: https://your-backend.railway.app

‚úÖ Team Assistant API
Endpoint	Method	Body	Description
/api/team/ask	POST	{query, user_id, llmMode, personalizationEnabled}	Natural Language –∑–∞–ø—Ä–æ—Å—ã (Perplexity + –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ñ–∏–ª—è)
ü§ñ Local LLM API
Endpoint	Method	Body	Description
/api/local-llm/ask	POST	{prompt, temperature, top_p}	–ü—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å –∫ Ollama
/api/local-llm/health	GET	-	–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Ollama
/api/local-llm/models	GET	-	–°–ø–∏—Å–æ–∫ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
üìä Analytics API
Endpoint	Method	Body	Description
/api/analytics/query	POST	{query}	–ü—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å –∫ –∞–Ω–∞–ª–∏—Ç–∏–∫–µ
/api/analytics/chat	POST	{query}	LLM-–æ–±—ë—Ä—Ç–∫–∞ (–æ—Ç–≤–µ—Ç + –∞–≥—Ä–µ–≥–∞—Ç—ã)
üìö Documents Pipeline
Endpoint	Method	Body	Description
/api/documents/index	POST	{directory, index_name}	–°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å
/api/documents/search	POST	{query, index_name, top_k}	–ü–æ–∏—Å–∫
ü§ñ RAG API
Endpoint	Method	Body	Description
/api/rag/ask	POST	{question, mode, topK}	RAG –∑–∞–ø—Ä–æ—Å
üí¨ Support Assistant
Endpoint	Method	Body	Description
/api/support/ask	POST	{user_id, question}	–ü–æ–¥–¥–µ—Ä–∂–∫–∞
‚úÖ Git Assistant API
Endpoint	Method	Body	Description
/api/assistant/command	POST	{command}	Git –∫–æ–º–∞–Ω–¥—ã
üß™ LLM Optimization API
Endpoint	Method	Body	Description
/api/llm/models	GET	-	–°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π, –ø—Ä–µ—Å–µ—Ç–æ–≤, –ø—Ä–æ–º–ø—Ç–æ–≤
/api/llm/optimized	POST	{prompt, temperature, ...}	–ó–∞–ø—Ä–æ—Å —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
/api/llm/test-config	POST	{prompt, configs[]}	–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
/api/llm/template	POST	{template_name, data, preset}	–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ–º–ø—Ç–∞
Environment Variables
Development (.env.example)
bash
# Perplexity AI
PERPLEXITY_API_KEY=pplx-xxxxxxxxxxxx
PERPLEXITY_MODEL=sonar

# Server
PORT=4000

# Git MCP (Local)
REPO_PATH=D:\perplexity-chat  # Windows: –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å

# Ollama (Local LLM)
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=gemma3:4b

# Analytics
ANALYTICS_CSV=data/events.csv
ANALYTICS_LOG=data/errors.log
ANALYTICS_JSON=data/funnel.json

# GitHub (optional)
GITHUB_TOKEN=ghp_xxxxxxxxxxxx
GITHUB_OWNER=Luno-o
GITHUB_REPO=perplexity-chat
Production - Railway (Backend)
bash
PERPLEXITY_API_KEY=<from GitHub Secrets>
PERPLEXITY_MODEL=sonar
REPO_PATH=/app/repo
PORT=4000
NODE_ENV=production
# Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –≤ production (—Ç–æ–ª—å–∫–æ –ª–æ–∫–∞–ª—å–Ω–æ)
Production - Vercel (Frontend)
bash
VITE_API_URL=https://your-backend.railway.app
NODE_VERSION=20
Team Assistant Features
üåê Perplexity Mode (Default) + –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è
‚úÖ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á–∞–º–∏ (—Å–æ–∑–¥–∞–Ω–∏–µ, –ø—Ä–æ—Å–º–æ—Ç—Ä, —É–¥–∞–ª–µ–Ω–∏–µ)
‚úÖ –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á —Å —É—á—ë—Ç–æ–º Git –∏–∑–º–µ–Ω–µ–Ω–∏–π
‚úÖ –°—Ç–∞—Ç—É—Å –ø—Ä–æ–µ–∫—Ç–∞ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞
‚úÖ Git –æ–ø–µ—Ä–∞—Ü–∏–∏ (status, commits, history)
‚úÖ RAG –ø–æ–∏—Å–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
‚úÖ –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (userPersonalizationService)
‚úÖ –§–∏–Ω–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ Perplexity —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º system prompt, –≤ –∫–æ—Ç–æ—Ä—ã–π –ø–æ–¥–º–µ—à–∏–≤–∞—é—Ç—Å—è:

–∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, –°–µ—Ä–≥–µ–π),

–ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã–π —è–∑—ã–∫ –∏ —Å—Ç–∏–ª—å,

—Å—Ç–µ–∫ (Node.js, React, Docker, MCP, Ollama),

—Ç–µ–∫—É—â–∏–π –ø—Ä–æ–µ–∫—Ç (perplexity-chat),

–ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ —Ñ–æ—Ä–º–∞—Ç—É –æ—Ç–≤–µ—Ç–æ–≤ (–∫—Ä–∞—Ç–∫–æ, —Å –∫–æ–¥–æ–º –∏ —Ç.–¥.). [file:77][file:84]

–ü—Ä–∏–º–µ—Ä—ã –∫–æ–º–∞–Ω–¥:

text
"–ü–æ–∫–∞–∂–∏ –≤—Å–µ –∑–∞–¥–∞—á–∏"
"–ß—Ç–æ –¥–µ–ª–∞—Ç—å –ø–µ—Ä–≤—ã–º?"
"–°—Ç–∞—Ç—É—Å –ø—Ä–æ–µ–∫—Ç–∞"
"–°–æ–∑–¥–∞–π –∑–∞–¥–∞—á—É: –∏—Å–ø—Ä–∞–≤–∏—Ç—å –±–∞–≥, –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç high"
"–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç RAG –≤ —ç—Ç–æ–º –ø—Ä–æ–µ–∫—Ç–µ?"
"–ü–æ–∫–∞–∂–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 –∫–æ–º–º–∏—Ç–æ–≤"
"–ö–∞–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å Docker?"
"–ö–∞–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å Docker –¥–ª—è perplexity-chat?"
ü§ñ Ollama Mode (Local LLM)
‚úÖ –ë—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã –±–µ–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞
‚úÖ –ü—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å (–≤—Å–µ –¥–∞–Ω–Ω—ã–µ –ª–æ–∫–∞–ª—å–Ω–æ)
‚úÖ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
‚úÖ –û–±—â–∏–µ –∑–Ω–∞–Ω–∏—è –∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
‚úÖ –ú–æ–¥–µ–ª–∏: gemma3:4b (3.3 GB), llama3.2:3b (2.0 GB)

–ê–∫—Ç–∏–≤–∞—Ü–∏—è:

–ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –Ω–∞ "ü§ñ Ollama" –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ Team Assistant.

–ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –Ω–∞–ø—Ä—è–º—É—é (–≤ —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏ Team Assistant —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç Perplexity; –ª–æ–∫–∞–ª—å–Ω–∞—è LLM –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –¥—Ä—É–≥–∏—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –∏ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∞ –≤ Team Assistant –ø–æ–∑–∂–µ). [file:83][file:84]

–ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤:

text
"–ß—Ç–æ —Ç–∞–∫–æ–µ MCP –ø—Ä–æ—Ç–æ–∫–æ–ª?"
"–û–±—ä—è—Å–Ω–∏ –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç RAG"
"–ö–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä?"
"–í —á—ë–º —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É REST –∏ GraphQL?"
üß™ LLM Optimization
–°—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ª–æ–∫–∞–ª—å–Ω–æ–π LLM:

‚úÖ –ü—Ä–æ—Å–º–æ—Ç—Ä –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ –ø—Ä–µ—Å–µ—Ç–æ–≤
‚úÖ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (temperature, top_p, top_k, num_predict, repeat_penalty)
‚úÖ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞–∑–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≥–æ—Ç–æ–≤—ã—Ö —à–∞–±–ª–æ–Ω–æ–≤ –ø—Ä–æ–º–ø—Ç–æ–≤

üìä Analytics Assistant
–ß–∞—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–≥–æ–≤ –∏ –ø—Ä–æ–¥—É–∫—Ç–æ–≤–æ–π –≤–æ—Ä–æ–Ω–∫–∏:

‚úÖ –í–æ–ø—Ä–æ—Å—ã –ø—Ä–æ —à–∞–≥–∏ –≤–æ—Ä–æ–Ω–∫–∏ –∏ drop-off –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
‚úÖ –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫ –ø–æ –º–∞—Ä—à—Ä—É—Ç–∞–º (/api/login, /api/signup –∏ —Ç.–ø.)
‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π
‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç —Å –ª–æ–∫–∞–ª—å–Ω–æ–π LLM (Ollama) –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤

–ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤:

text
"–ù–∞ –∫–∞–∫–æ–º —à–∞–≥–µ –≤–æ—Ä–æ–Ω–∫–∏ –±–æ–ª—å—à–µ –≤—Å–µ–≥–æ –ø–æ—Ç–µ—Ä—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π?"
"–ö–∞–∫–æ–π –º–∞—Ä—à—Ä—É—Ç –∏–º–µ–µ—Ç –±–æ–ª—å—à–µ –≤—Å–µ–≥–æ –æ—à–∏–±–æ–∫?"
"–î–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –≤–æ—Ä–æ–Ω–∫–∏"
Monitoring & Debugging
Railway Logs
bash
railway logs --service backend --tail
Vercel Logs
bash
vercel logs https://your-app.vercel.app
Ollama Logs
bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞
curl http://localhost:11434

# –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
ollama list

# –ó–∞–ø—É—Å–∫ –º–æ–¥–µ–ª–∏
ollama run gemma3:4b

# –¢–µ—Å—Ç —á–µ—Ä–µ–∑ API
curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{"model": "gemma3:4b", "prompt": "Hello", "stream": false}'
Health Check
bash
# Backend
curl https://your-backend.railway.app/api/health

# Response: {"status": "ok", "timestamp": "2026-01-20T..."}

# Local LLM
curl http://localhost:4000/api/local-llm/health

# Response: {"status": "ok", "url": "http://localhost:11434", "model": "gemma3:4b"}
Testing
Local Testing
bash
# Backend health
curl http://localhost:4000/api/health

# Team Assistant test (Perplexity + personalization)
curl -X POST http://localhost:4000/api/team/ask \
  -H "Content-Type: application/json" \
  -d '{"query": "–ö–∞–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å Docker?", "user_id": "luno-o", "llmMode": "perplexity", "personalizationEnabled": true}'

# Local LLM test (Ollama)
curl -X POST http://localhost:4000/api/local-llm/ask \
  -H "Content-Type: application/json" \
  -d '{"prompt": "–ß—Ç–æ —Ç–∞–∫–æ–µ MCP?"}'

# Analytics test
curl -X POST http://localhost:4000/api/analytics/chat \
  -H "Content-Type: application/json" \
  -d "{\"query\": \"–ù–∞ –∫–∞–∫–æ–º —à–∞–≥–µ –≤–æ—Ä–æ–Ω–∫–∏ –±–æ–ª—å—à–µ –ø–æ—Ç–µ—Ä—å?\"}"
Production Testing
bash
# Frontend (Vercel)
curl https://your-app.vercel.app

# Backend (Railway)
curl https://your-backend.railway.app/api/health

# Team Assistant
curl -X POST https://your-backend.railway.app/api/team/ask \
  -H "Content-Type: application/json" \
  -d '{"query": "–ü–æ–∫–∞–∂–∏ –∑–∞–¥–∞—á–∏"}'
Troubleshooting
Railway Deployment Fails
Error: Railpack could not determine how to build

Solution:

–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Root Directory: /server (Settings ‚Üí Source)

–°–æ–∑–¥–∞–π—Ç–µ railway.json —Å startCommand

–ü—Ä–æ–≤–µ—Ä—å—Ç–µ package.json –∏–º–µ–µ—Ç start —Å–∫—Ä–∏–ø—Ç

Error: Module not found –≤ production

Solution:

–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≤ package.json (–Ω–µ –≤ devDependencies)

–£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ npm install –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–µ—Ä–µ–¥ start

Vercel Deployment Fails
Error: Build failed

Solution:

–ü—Ä–æ–≤–µ—Ä—å—Ç–µ vercel.json ‚Üí buildCommand –∏ outputDirectory

–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Node.js –≤–µ—Ä—Å–∏—é —á–µ—Ä–µ–∑ NODE_VERSION env var

–£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ npm run build —Ä–∞–±–æ—Ç–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ

Error: 404 on refresh

Solution: –î–æ–±–∞–≤—å—Ç–µ –≤ vercel.json:

json
{
  "routes": [
    { "src": "/[^.]+", "dest": "/", "status": 200 }
  ]
}
Ollama Issues
Error: Connection refused (localhost:11434)

Solution:

bash
# Windows
ollama serve

# –ü—Ä–æ–≤–µ—Ä–∫–∞
curl http://localhost:11434
Error: Model not found

Solution:

bash
# –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
ollama list

# –°–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª—å
ollama pull gemma3:4b

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤ –∫–æ–¥–µ
# server/.env: OLLAMA_MODEL=gemma3:4b
Error: 404 on /api/generate

Solution:

–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–µ—Ä—Å–∏—é Ollama: ollama --version

–û–±–Ω–æ–≤–∏—Ç–µ –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π: —Å–∫–∞—á–∞–π—Ç–µ —Å ollama.com

–ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ: ollama serve

CORS Errors
Error: Access-Control-Allow-Origin

Solution (server/index.js):

javascript
app.use(cors({
  origin: process.env.NODE_ENV === 'production' 
    ? 'https://your-app.vercel.app'
    : 'http://localhost:5173'
}));
Analytics Issues
Error: __dirname is not defined –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–Ω–¥–µ–∫—Å–æ–≤

Solution: –í —Ñ–∞–π–ª–∞—Ö, –≥–¥–µ —á–∏—Ç–∞—é—Ç—Å—è –∏–Ω–¥–µ–∫—Å—ã (ragService, analyticsService), –¥–æ–±–∞–≤—å—Ç–µ:

javascript
import path from "path";
import { fileURLToPath } from "url";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
Error: analyticsService –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç—ã–µ –∞–≥—Ä–µ–≥–∞—Ç—ã

Solution: –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ data/events.csv, data/errors.log, data/funnel.json —Å—É—â–µ—Å—Ç–≤—É—é—Ç –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏

–í–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
–í–µ—Ä—Å–∏—è: v1.5.0
–î–∞—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: 2026-01-27 22:27 MSK
–°—Ç–∞—Ç—É—Å: ‚úÖ Production Ready + Local LLM + Analytics + –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è Team Assistant

–ò–∑–º–µ–Ω–µ–Ω–∏—è v1.5.0:
üÜï userPersonalizationService.js

–•—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª–µ–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ server/userProfiles/*.json

–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ system prompt (—è–∑—ã–∫, —Å—Ç–∏–ª—å, —Å—Ç–µ–∫, –ø—Ä–æ–µ–∫—Ç, —Ç–æ–Ω)

–í–æ–∑–≤—Ä–∞—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª—è –¥–ª—è UI (–∏–º—è, —Ä–æ–ª—å, –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è). [file:77]

üÜï –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π Team Assistant

teamAssistantService.processTeamQuery:

–ø—Ä–∏–Ω–∏–º–∞–µ—Ç userId, llmMode, personalizationEnabled,

–∏—Å–ø–æ–ª—å–∑—É–µ—Ç MCP (Tasks, Git, RAG) –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö,

—Å–æ–±–∏—Ä–∞–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π system prompt —á–µ—Ä–µ–∑ userPersonalizationService,

–≤—ã–∑—ã–≤–∞–µ—Ç Perplexity (sonar) —Å —ç—Ç–∏–º system prompt –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –æ—Ç–≤–µ—Ç–∞. [file:84]

–ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ–ª–∞–≥–æ–≤ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö:

result.personalized,

result.personalizationProfile,

result.llmUsed. [file:84]

üîÑ TeamAssistantPage.jsx

–î–æ–±–∞–≤–ª–µ–Ω–∞ –∫–Ω–æ–ø–∫–∞ ‚ÄúüéØ –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è: –í–ö–õ/–í–´–ö–õ‚Äù.

–ü—Ä–∏ –≤–∫–ª—é—á–µ–Ω–∏–∏:

–∑–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (/api/personalization/profile/:user_id),

–æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤ /api/team/ask —Ñ–ª–∞–≥ personalizationEnabled: true –∏ user_id: "luno-o",

–æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –±–µ–π–¥–∂–∏ ‚Äú–ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ‚Äù –∏ –∏–º—è –ø—Ä–æ—Ñ–∏–ª—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, –°–µ—Ä–≥–µ–π). [file:19]

‚úÖ /api/team/ask

–û–±–Ω–æ–≤–ª—ë–Ω —ç–Ω–¥–ø–æ–∏–Ω—Ç –≤ server/index.js:

–ø—Ä–∏–Ω–∏–º–∞–µ—Ç {query, user_id, llmMode, personalizationEnabled},

–ª–æ–≥–∏—Ä—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã,

–ø—Ä–æ–∫–∏–¥—ã–≤–∞–µ—Ç –∏—Ö –≤ processTeamQuery. [file:85]

–ò–∑–º–µ–Ω–µ–Ω–∏—è v1.4.0:
üÜï analyticsService.js ‚Äî –ø–æ–ª–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è:

loadAndParse() ‚Äî —á–∏—Ç–∞–µ—Ç events.csv, errors.log, funnel.json

aggregate() ‚Äî —Å—á–∏—Ç–∞–µ—Ç –≤–æ—Ä–æ–Ω–∫—É, drop-off –ø–æ —à–∞–≥–∞–º, –æ—à–∏–±–∫–∏ –ø–æ –º–∞—Ä—à—Ä—É—Ç–∞–º

analyzeData() ‚Äî –≥–æ—Ç–æ–≤–∏—Ç JSON-–∞–≥—Ä–µ–≥–∞—Ç—ã –∏ —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—É—é LLM

üÜï analyticsChatService.js ‚Äî LLM-–æ–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ analyticsService

üÜï analyticsConfig.js ‚Äî –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—É—Ç–µ–π –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö

üÜï envBootstrap.js ‚Äî bootstrap –æ–∫—Ä—É–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ file.env

üÜï check-env.js ‚Äî —É—Ç–∏–ª–∏—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è

üÜï data/ ‚Äî –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏:

events.csv (—Å–æ–±—ã—Ç–∏—è —Å –º–∞—Ä—à—Ä—É—Ç–∞–º–∏ –∏ —Å—Ç–∞—Ç—É—Å-–∫–æ–¥–∞–º–∏)

errors.log (–ª–æ–≥–∏ –æ—à–∏–±–æ–∫ —Å route –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö)

funnel.json (–≤–æ—Ä–æ–Ω–∫–∞ —Å —à–∞–≥–∞–º–∏ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π)

üÜï AnalyticsPage.jsx + –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã ‚Äî UI –¥–ª—è Analytics Assistant

‚úÖ /api/analytics/query –∏ /api/analytics/chat —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –≤ index.js

–ò–∑–º–µ–Ω–µ–Ω–∏—è v1.3.0:
ü§ñ –î–æ–±–∞–≤–ª–µ–Ω–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –ª–æ–∫–∞–ª—å–Ω–æ–π LLM (Ollama)

server/localLlmClient.js - –∫–ª–∏–µ–Ω—Ç –¥–ª—è Ollama API

server/teamAssistantService.js - –æ–±–Ω–æ–≤–ª—ë–Ω —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ª–æ–∫–∞–ª—å–Ω–æ–π LLM (–≤ v1.5.0 —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –ø–µ—Ä–µ–Ω–µ—Å—ë–Ω –Ω–∞ Perplexity, –ª–æ–∫–∞–ª—å–Ω–∞—è LLM –æ—Å—Ç–∞—ë—Ç—Å—è –¥–ª—è –¥—Ä—É–≥–∏—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤)

client/src/pages/TeamAssistantPage.jsx - –¥–æ–±–∞–≤–ª–µ–Ω LLM switcher

–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é Ollama

–ò–∑–º–µ–Ω–µ–Ω–∏—è v1.2.0:
üöÄ –î–æ–±–∞–≤–ª–µ–Ω CI/CD —á–µ—Ä–µ–∑ GitHub Actions

–î–µ–ø–ª–æ–π –Ω–∞ Vercel (Frontend) + Railway (Backend)

GitHub Secrets integration

–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ deployment

Roadmap
v1.6.0 (Next Release)
üéØ Streaming –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–π LLM –≤ UI Team Assistant

üîÑ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä LLM (routing) –º–µ–∂–¥—É Perplexity –∏ Ollama

üìà –ë–æ–ª–µ–µ —Ç–æ–Ω–∫–∞—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è (–∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ–µ–∫—Ç–∞, –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏, —Å—Ç–∞—Ç—É—Å Git)

üìå –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

v2.0.0 (Future)
ü§ñ Advanced RAG —Å re-ranking

üé≠ Multi-modal LLM (vision models)

üîê Fine-tuned models –¥–ª—è domain-specific –∑–∞–¥–∞—á

üì± Mobile apps (React Native)

üåê WebSocket –¥–ª—è real-time updates

–õ–∏—Ü–µ–Ω–∑–∏—è
MIT

–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞: AI Challenge 23 - MCP Integration + RAG + CI/CD + Local LLM + Analytics + Personalized Team Assistant
–°—Ç–∞—Ç—É—Å: ‚úÖ Production Ready (v1.5.0)
–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: 2026-01-27 22:27 MSK